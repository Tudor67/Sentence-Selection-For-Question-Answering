{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. [Loading preprocessed data](#1.-Loading-preprocessed-data)  \n",
    "2. [Solutions](#2.-Solutions)  \n",
    "    2.1 [Random approach](#2.1-Random-approach)  \n",
    "    2.2 [String kernels](#2.2-String-kernels)   \n",
    "      2.2.1 [Spectrum kernel](#2.2.1-Spectrum-kernel)  \n",
    "      2.2.2 [Presence kernel](#2.2.2-Presence-kernel)  \n",
    "      2.2.3 [Intersection kernel](#2.2.3-Intersection-kernel)  \n",
    "    2.3 [Sentence similarity](#2.3-Sentence-similarity)   \n",
    "3. [Results](#3.-Results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "IN_PATH = '../data/squad/'\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data = []\n",
    "    with open(filename) as f:\n",
    "        data = json.load(f)  \n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data(IN_PATH + 'train-v1.1-preprocessed.json')\n",
    "dev = load_data(IN_PATH + 'dev-v1.1-preprocessed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's import evaluation module. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Let's define a generic function to run different methods/solutions/approaches. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_method(method, question_words, candidate_answers_words):\n",
    "    if method == 'random_solution':\n",
    "        return random_solution(len(candidate_answers_words))\n",
    "    elif 'kernel' in method:\n",
    "        return kernel_solution(question_words, candidate_answers_words, method)\n",
    "    elif 'sentence_similarity' in method:\n",
    "        return sentence_similarity_solution(question_words, candidate_answers_words)\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def run(dataset, method='random_solution'):\n",
    "    results = {'Method': method, 'Prec@1': [], 'Prec@5': [], 'Prec@10': [],\n",
    "               'AvgPrec': [], 'MAP': 0}\n",
    "    idx = 0\n",
    "    for article in dataset['data']:\n",
    "        for qas_context in article['paragraphs']:\n",
    "            # get the number of candidate answers\n",
    "            nr_candidate_answers = qas_context['nr_candidate_answers']\n",
    "\n",
    "            for qas in qas_context['qas']:\n",
    "                # get answers' labels from context\n",
    "                answer_labels = list()\n",
    "                for answer in qas['answers']:\n",
    "                    answer_labels.append(answer['answer_label'])\n",
    "                    \n",
    "                # trying to keep the same notation\n",
    "                question_words = qas['question_words']\n",
    "                candidate_answers_words = qas_context['context_sentences_words']\n",
    "                y = answer_labels\n",
    "                \n",
    "                # run a method\n",
    "                y_pred = run_method(method, question_words, candidate_answers_words)\n",
    "                \n",
    "                # evaluation\n",
    "                results['Prec@1'].append(evaluation.precision_at_k(y_pred, y, k=1))\n",
    "                #results['Prec@5'].append(evaluation.precision_at_k(y_pred, y, k=5))\n",
    "                #results['Prec@10'].append(evaluation.precision_at_k(y_pred, y, k=10))\n",
    "                results['AvgPrec'].append(evaluation.average_precision(y_pred, y))\n",
    "                \n",
    "                '''\n",
    "                if idx == 414:\n",
    "                    print('idx: {}\\n'.format(idx))\n",
    "                    print('question: {}\\n'.format(question))\n",
    "                    print('candidate_answers:')\n",
    "                    pprint(candidate_answers)\n",
    "                    print('context length', len(qas_context['context']))\n",
    "                    print('context_sentences sum(length)', np.sum([len(s) for s in qas_context['context_sentences']]))\n",
    "                    for answer in qas['answers']:\n",
    "                        print('answer_start', answer['answer_start'])\n",
    "                    print('y_pred: {}\\n'.format(y_pred))\n",
    "                    print('y: {}\\n'.format(y))\n",
    "                '''\n",
    "                \n",
    "                idx += 1\n",
    "                \n",
    "                if idx % 10000 == 0:\n",
    "                    print('{}'.format(idx))\n",
    "                \n",
    "                \n",
    "                \n",
    "    # evaluation (MAP - mean average precision)\n",
    "    results['MAP'] = np.mean(results['AvgPrec'])\n",
    "    results['StdAP'] = np.std(results['AvgPrec'])\n",
    "    results['AvgPrec@1'] = np.mean(results['Prec@1'])\n",
    "    results['StdPrec@1'] = np.std(results['Prec@1'])\n",
    "    #results['AvgPrec@5'] = np.mean(results['Prec@5'])\n",
    "    #results['AvgPrec@10'] = np.mean(results['Prec@10'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Random approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def random_solution(n):\n",
    "    return np.random.permutation(n).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(results):\n",
    "    print('Method: {}'.format(results['Method']))\n",
    "    print('AvgPrec@1: {} (std = {})'.format(results['AvgPrec@1'], results['StdPrec@1']))\n",
    "    print('MAP: {} (std = {})'.format(results['MAP'], results['StdAP']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "Method: random_solution\n",
      "AvgPrec@1: 0.247263096611 (std = 0.431420974994)\n",
      "MAP: 0.49216751562 (std = 0.312040888335)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_results = run(train, method='random_solution')\n",
    "write_results(train_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 String kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** I will try to use string kernels at word level even if they are used as character-level method. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Aux methods **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def num(word, sentence_words):\n",
    "    count = 0\n",
    "    for w in sentence_words:\n",
    "        if word == w:\n",
    "            count += 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Spectrum kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def spectrum_kernel_value(question_words, sentence_words):\n",
    "    kernel_value = 0\n",
    "    vocab_inters = set(question_words).intersection(sentence_words)\n",
    "    \n",
    "    for word in vocab_inters:\n",
    "        kernel_value += num(word, question_words) * num(word, sentence_words)\n",
    "        \n",
    "    return kernel_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Presence kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def presence_kernel_value(question_words, sentence_words):\n",
    "    kernel_value = 0\n",
    "    vocab_inters = set(question_words).intersection(sentence_words)\n",
    "    \n",
    "    return len(vocab_inters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Intersection kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersection_kernel_value(question_words, sentence_words):\n",
    "    kernel_value = 0\n",
    "    vocab_inters = set(question_words).intersection(sentence_words)\n",
    "    \n",
    "    for word in vocab_inters:\n",
    "        kernel_value += min(num(word, question_words), num(word, sentence_words))\n",
    "        \n",
    "    return kernel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel_solution(question_words, context_sentences, kernel_type='intersection_kernel'):\n",
    "    scores = {}\n",
    "    \n",
    "    for sentence_label in range(len(context_sentences)):\n",
    "        kernel_value = 0\n",
    "        if kernel_type == 'spectrum_kernel':\n",
    "            kernel_value = spectrum_kernel_value(question_words, context_sentences[sentence_label])\n",
    "        elif kernel_type == 'presence_kernel':\n",
    "            kernel_value = presence_kernel_value(question_words, context_sentences[sentence_label])\n",
    "        elif kernel_type == 'intersection_kernel':\n",
    "            kernel_value = intersection_kernel_value(question_words, context_sentences[sentence_label])\n",
    "        \n",
    "        scores[sentence_label] = kernel_value\n",
    "        \n",
    "    labels = sorted(scores, key=scores.get, reverse=True)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "Method: spectrum_kernel\n",
      "AvgPrec@1: 0.677010406812 (std = 0.46761877195)\n",
      "MAP: 0.802783152628 (std = 0.282561751016)\n",
      "\n",
      "\n",
      "10000\n",
      "Method: presence_kernel\n",
      "AvgPrec@1: 0.793093661306 (std = 0.405087775306)\n",
      "MAP: 0.871033907576 (std = 0.244495759616)\n",
      "\n",
      "\n",
      "10000\n",
      "Method: intersection_kernel\n",
      "AvgPrec@1: 0.790350047304 (std = 0.407058779577)\n",
      "MAP: 0.869128338505 (std = 0.246021270821)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = ['spectrum_kernel', 'presence_kernel', 'intersection_kernel']\n",
    "for method in methods:\n",
    "    dev_results = run(dev, method)\n",
    "    write_results(dev_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sentence similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** The code for max sentence similarity is taken from this site: https://nlpforhackers.io/wordnet-sentence-similarity/.  \n",
    "This algorithm is proposed by Mihalcea et al. in the paper [Corpus-based and Knowledge-based Measures\n",
    "of Text Semantic Similarity](https://www.aaai.org/Papers/AAAI/2006/AAAI06-123.pdf).  \n",
    "More info about word similarities cand be found here: http://www.nltk.org/howto/wordnet.html. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    " \n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    \"\"\" Convert between a Penn Treebank tag to a simplified Wordnet tag \"\"\"\n",
    "    if tag.startswith('N'):\n",
    "        return 'n'\n",
    " \n",
    "    if tag.startswith('V'):\n",
    "        return 'v'\n",
    " \n",
    "    if tag.startswith('J'):\n",
    "        return 'a'\n",
    " \n",
    "    if tag.startswith('R'):\n",
    "        return 'r'\n",
    " \n",
    "    return None\n",
    " \n",
    "\n",
    "def tagged_to_synset(word, tag):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag is None:\n",
    "        return None\n",
    " \n",
    "    try:\n",
    "        return wn.synsets(word, wn_tag)[0]\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return None\n",
    "\n",
    " \n",
    "def sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the sentence similarity using Wordnet \"\"\"\n",
    "    # Tokenize and tag\n",
    "    sentence1 = pos_tag(word_tokenize(sentence1))\n",
    "    sentence2 = pos_tag(word_tokenize(sentence2))\n",
    " \n",
    "    # Get the synsets for the tagged words\n",
    "    synsets1 = [tagged_to_synset(*tagged_word) for tagged_word in sentence1]\n",
    "    synsets2 = [tagged_to_synset(*tagged_word) for tagged_word in sentence2]\n",
    " \n",
    "    # Filter out the Nones\n",
    "    synsets1 = [ss for ss in synsets1 if ss]\n",
    "    synsets2 = [ss for ss in synsets2 if ss]\n",
    " \n",
    "    score, count = 0.0, 0\n",
    " \n",
    "    # For each word in the first sentence\n",
    "    for synset in synsets1:\n",
    "        # Get the similarity value of the most similar word in the other sentence\n",
    "        similarities = [synset.wup_similarity(ss) for ss in synsets2]\n",
    "        best_score = 0\n",
    "        if similarities:\n",
    "            best_score = max(similarities)\n",
    " \n",
    "        # Check that the similarity could have been computed\n",
    "        if best_score is not None:\n",
    "            score += best_score\n",
    "            count += 1\n",
    " \n",
    "    # Average the values\n",
    "    if count > 0:\n",
    "        score /= count\n",
    "    \n",
    "    return score\n",
    "\n",
    "\n",
    "def symmetric_sentence_similarity(sentence1, sentence2):\n",
    "    \"\"\" compute the symmetric sentence similarity using Wordnet \"\"\"\n",
    "    return (sentence_similarity(sentence1, sentence2) + sentence_similarity(sentence2, sentence1)) / 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_similarity_solution(question_words, candidate_answers_words):\n",
    "    question_sentence = \" \".join(question_words)\n",
    "    scores = {}\n",
    "    \n",
    "    for sentence_label in range(len(candidate_answers_words)):\n",
    "        candidate_answer_sentence = \" \".join(candidate_answers_words[sentence_label])\n",
    "        similarity = symmetric_sentence_similarity(question_sentence, candidate_answer_sentence)\n",
    "        scores[sentence_label] = similarity\n",
    "        \n",
    "    labels = sorted(scores, key=scores.get, reverse=True)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** First results **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Results---train_set---\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "Method: random_solution\n",
      "AvgPrec@1: 0.243221954589 (std = 0.429028012366)\n",
      "MAP: 0.489592709539 (std = 0.310652522653)\n",
      "\n",
      "\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "Method: spectrum_kernel\n",
      "AvgPrec@1: 0.657781481524 (std = 0.474452320142)\n",
      "MAP: 0.793677682596 (std = 0.294664462039)\n",
      "\n",
      "\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "Method: presence_kernel\n",
      "AvgPrec@1: 0.762463041816 (std = 0.4255739086)\n",
      "MAP: 0.856392399475 (std = 0.264111287787)\n",
      "\n",
      "\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "Method: intersection_kernel\n",
      "AvgPrec@1: 0.759483555748 (std = 0.427397103753)\n",
      "MAP: 0.85435303237 (std = 0.265727202849)\n",
      "\n",
      "\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "Method: sentence_similarity\n",
      "AvgPrec@1: 0.707610817475 (std = 0.454860141656)\n",
      "MAP: 0.819571496116 (std = 0.288932461455)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nprint('---Results---dev_set---')\\nfor method in methods:\\n    dev_results = run(dev, method)\\n    write_results(dev_results)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "methods = ['random_solution', 'spectrum_kernel', 'presence_kernel', 'intersection_kernel', 'sentence_similarity']\n",
    "\n",
    "\n",
    "print('---Results---train_set---')\n",
    "for method in methods:\n",
    "    train_results = run(train, method)\n",
    "    write_results(train_results)\n",
    "\n",
    "\n",
    "'''\n",
    "print('---Results---dev_set---')\n",
    "for method in methods:\n",
    "    dev_results = run(dev, method)\n",
    "    write_results(dev_results)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
