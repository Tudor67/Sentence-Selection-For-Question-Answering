{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. [Loading preprocessed data](#1.-Loading-preprocessed-data)  \n",
    "2. [Loading pretrained word embeddings](#2.-Loading-pretrained-word-embeddings)  \n",
    "3. [Classification](#3.-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "IN_PATH = '../data/squad/'\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data_frame = pd.read_json(filename)\n",
    "    data = data_frame.to_dict(orient='list')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data(IN_PATH + 'train-v1.1-preprocessed.json')\n",
    "dev = load_data(IN_PATH + 'dev-v1.1-preprocessed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "WORD2VEC_PATH = '../word_embeddings/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "word2vec_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pretrained_word_embeddings(sentence, word_emb_dims=300):\n",
    "    global word2vec_model\n",
    "    \n",
    "    if word2vec_model is None:\n",
    "        print('load word2vec_model')\n",
    "        word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\n",
    "\n",
    "    word_embeddings = np.zeros(word_emb_dims)\n",
    "    word_emb_nr = 0\n",
    "\n",
    "    for word in sentence:\n",
    "        if word2vec_model.vocab.has_key(word):\n",
    "            word_embeddings += word2vec_model.word_vec(word)\n",
    "            word_emb_nr += 1\n",
    "\n",
    "    # a sentence is represented by the average of word_embbedings\n",
    "    if word_emb_nr != 0:\n",
    "        word_embeddings = word_embeddings / word_emb_nr\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load word2vec_model\n"
     ]
    }
   ],
   "source": [
    "get_pretrained_word_embeddings(['today', 'is', 'wednesday']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataset, q_a_combination_method):\n",
    "    train_x = list()\n",
    "    train_y = list()\n",
    "    train_steps = list()\n",
    "    train_labels = list()\n",
    "    \n",
    "    for article in tqdm(dataset['data']):\n",
    "        for qas_context in article['paragraphs']:\n",
    "            for qas in qas_context['qas']:\n",
    "                question_words = qas['question_words']\n",
    "                question_embedding = get_pretrained_word_embeddings(question_words)\n",
    "                \n",
    "                candidate_sentences_embeddings = list()\n",
    "                for sentence in qas_context['context_sentences_words']:\n",
    "                    candidate_sentences_embeddings.append(get_pretrained_word_embeddings(sentence))\n",
    "                \n",
    "                labels = set([d['answer_label'] for d in qas['answers']])\n",
    "                train_labels.append(labels)\n",
    "                \n",
    "                train_steps.append(len(candidate_sentences_embeddings))\n",
    "                \n",
    "                for i in range(len(candidate_sentences_embeddings)):\n",
    "                    feature_vector = []\n",
    "                    if q_a_combination_method == 'concatenation':\n",
    "                        feature_vector = np.concatenate((question_embedding,\n",
    "                                                         candidate_sentences_embeddings[i]))\n",
    "                    elif q_a_combination_method == 'diff_abs':\n",
    "                        feature_vector = np.abs(question_embedding - \n",
    "                                                candidate_sentences_embeddings[i])\n",
    "                    elif q_a_combination_method == 'diff_sqr':\n",
    "                        feature_vector = np.square(question_embedding - \n",
    "                                                   candidate_sentences_embeddings[i])\n",
    "                    elif q_a_combination_method == 'sum':\n",
    "                        feature_vector = question_embedding + candidate_sentences_embeddings[i]\n",
    "                    elif q_a_combination_method == 'dot_product':\n",
    "                        feature_vector = question_embedding * candidate_sentences_embeddings[i]\n",
    "                    elif q_a_combination_method == 'min':\n",
    "                        feature_vector = np.minimum(question_embedding,\n",
    "                                                    candidate_sentences_embeddings[i])            \n",
    "                    elif q_a_combination_method == 'max':\n",
    "                        feature_vector = np.maximum(question_embedding,\n",
    "                                                    candidate_sentences_embeddings[i])  \n",
    "                        \n",
    "                    train_x.append(feature_vector)\n",
    "                    label = i in labels\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return (train_x, train_y, train_steps, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:29<00:00, 14.81it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.02it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y, _, train_labels) = get_features(train, 'diff_abs')\n",
    "(dev_x, dev_y, dev_steps, dev_labels) = get_features(dev, 'diff_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447101\n",
      "87599\n",
      "359502\n"
     ]
    }
   ],
   "source": [
    "print((len(train_x)))\n",
    "print(np.sum(train_y == np.array([1]*len(train_y))))\n",
    "print(np.sum(train_y == np.array([0]*len(train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53967\n",
      "11436\n",
      "42531\n"
     ]
    }
   ],
   "source": [
    "print((len(dev_x)))\n",
    "print(np.sum(dev_y == np.array([1]*len(dev_y))))\n",
    "print(np.sum(dev_y == np.array([0]*len(dev_y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(train_x, train_y, test_x):\n",
    "    pred = np.zeros(len(test_x))\n",
    "\n",
    "    lr_model = LogisticRegression(C=1, dual=True)\n",
    "    lr_model.fit(train_x, train_y)\n",
    "    pred = lr_model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    return (lr_model, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, dev_preds) = logistic_regression(train_x, train_y, dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.35104771,  0.18424411,  0.14537631,  0.23334672,  0.38269845,\n",
       "        0.20189636,  0.17294577,  0.24725637,  0.05252859,  0.05112427])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(53967,)\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_preds))\n",
    "print(dev_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_scores(y_pred, steps_lengths):\n",
    "    pred_scores_id = list()\n",
    "    steps_lengths_sum = 0\n",
    "    \n",
    "    for step_length in steps_lengths:\n",
    "        scores = {}\n",
    "        for idx in range(step_length):\n",
    "            scores[idx] = y_pred[steps_lengths_sum + idx]\n",
    "        \n",
    "        sorted_scores_id = sorted(scores, key=scores.get, reverse=True)\n",
    "        pred_scores_id.append(sorted_scores_id)\n",
    "        \n",
    "        steps_lengths_sum += step_length\n",
    "        \n",
    "    return pred_scores_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores_id = extract_scores(dev_preds, dev_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n",
      "53967\n",
      "10570\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_scores_id))\n",
    "print(len(dev_y))\n",
    "print(len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 1, 2], [0, 3, 1, 2], [3, 2, 0, 1], [0, 1, 3, 2], [3, 2, 0, 1]]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(pred_scores_id[0:5])\n",
    "print(type(pred_scores_id[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, False, False]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(dev_y[0:5])\n",
    "print(type(dev_y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set([1]), set([1]), set([2]), set([1]), set([3])]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(dev_labels[0:5])\n",
    "print(type(dev_labels[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results = evaluation.get_results(pred_scores_id, dev_labels, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(results):\n",
    "    print('Method: {}'.format(results['Method']))\n",
    "    print('AvgPrec@1: {} (std = {})'.format(results['AvgPrec@1'], results['StdPrec@1']))\n",
    "    print('MAP: {} (std = {})'.format(results['MAP'], results['StdAP']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev\n",
      "AvgPrec@1: 0.734720908231 (std = 0.441481704309)\n",
      "MAP: 0.832476062341 (std = 0.273161211053)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_results(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_x\n",
    "del train_y\n",
    "del dev_x\n",
    "del dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_a_combination_method = ['concatenation', 'diff_abs', 'diff_sqr', \n",
    "                          'sum', 'dot_product', 'min', 'max']\n",
    "\n",
    "def run_LR(q_a_combination_method):\n",
    "    for q_a_comb in q_a_combination_method:\n",
    "        # feature extraction\n",
    "        (train_x, train_y, train_steps, train_labels) = get_features(train, q_a_comb)\n",
    "        (dev_x, dev_y, dev_steps, dev_labels) = get_features(dev, q_a_comb)\n",
    "        print(q_a_comb, len(train_x[0]))\n",
    "        \n",
    "        # dev set\n",
    "        (lr_model, dev_preds) = logistic_regression(train_x, train_y, dev_x)\n",
    "        dev_pred_scores_id = extract_scores(dev_preds, dev_steps)\n",
    "        \n",
    "        dev_results = evaluation.get_results(dev_pred_scores_id, dev_labels, \n",
    "                                             'dev [' + q_a_comb + ']')\n",
    "        write_results(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:29<00:00, 15.02it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('concatenation', 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/442 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [concatenation]\n",
      "AvgPrec@1: 0.326584673605 (std = 0.46896388408)\n",
      "MAP: 0.557686249614 (std = 0.317339845347)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:35<00:00, 12.33it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diff_abs', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:50,  8.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [diff_abs]\n",
      "AvgPrec@1: 0.734720908231 (std = 0.441481704309)\n",
      "MAP: 0.832476062341 (std = 0.273161211053)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:29<00:00, 14.93it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diff_sqr', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:49,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [diff_sqr]\n",
      "AvgPrec@1: 0.753169347209 (std = 0.431167347597)\n",
      "MAP: 0.842604529743 (std = 0.268318625504)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:28<00:00, 15.71it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sum', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:54,  8.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [sum]\n",
      "AvgPrec@1: 0.314191106906 (std = 0.464192907364)\n",
      "MAP: 0.547317845517 (std = 0.316215470134)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:28<00:00, 15.70it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dot_product', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:50,  8.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [dot_product]\n",
      "AvgPrec@1: 0.676253547777 (std = 0.467904570288)\n",
      "MAP: 0.801636720479 (std = 0.282876403657)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:28<00:00, 15.43it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('min', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:50,  8.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [min]\n",
      "AvgPrec@1: 0.721097445601 (std = 0.448459495996)\n",
      "MAP: 0.826097043133 (std = 0.274701457339)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:28<00:00, 15.46it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max', 300)\n",
      "Method: dev [max]\n",
      "AvgPrec@1: 0.720340586566 (std = 0.44883184592)\n",
      "MAP: 0.825343018522 (std = 0.275648882826)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_LR(q_a_combination_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
