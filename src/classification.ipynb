{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. [Loading preprocessed data](#1.-Loading-preprocessed-data)  \n",
    "2. [Loading pretrained word embeddings](#2.-Loading-pretrained-word-embeddings)  \n",
    "3. [Classification](#3.-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from input_output import load_data, write_results\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "IN_PATH = '../data/squad/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data(IN_PATH + 'train-v1.1-preprocessed.json')\n",
    "dev = load_data(IN_PATH + 'dev-v1.1-preprocessed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "WORD2VEC_PATH = '../word_embeddings/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "word2vec_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pretrained_word_embeddings(sentence, word_emb_dims=300):\n",
    "    global word2vec_model\n",
    "    \n",
    "    if word2vec_model is None:\n",
    "        print('load word2vec_model')\n",
    "        word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\n",
    "\n",
    "    word_embeddings = np.zeros(word_emb_dims)\n",
    "    word_emb_nr = 0\n",
    "\n",
    "    for word in sentence:\n",
    "        if word2vec_model.vocab.has_key(word):\n",
    "            word_embeddings += word2vec_model.word_vec(word)\n",
    "            word_emb_nr += 1\n",
    "\n",
    "    # a sentence is represented by the average of word_embbedings\n",
    "    if word_emb_nr != 0:\n",
    "        word_embeddings = word_embeddings / word_emb_nr\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load word2vec_model\n"
     ]
    }
   ],
   "source": [
    "get_pretrained_word_embeddings(['today', 'is', 'wednesday']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(dataset, q_a_combination_method):\n",
    "    train_x = list()\n",
    "    train_y = list()\n",
    "    train_steps = list()\n",
    "    train_labels = list()\n",
    "    \n",
    "    for article in tqdm(dataset['data']):\n",
    "        for qas_context in article['paragraphs']:\n",
    "            for qas in qas_context['qas']:\n",
    "                question_words = qas['question_lemmas_without_stopwords']\n",
    "                question_embedding = get_pretrained_word_embeddings(question_words)\n",
    "                \n",
    "                candidate_sentences_embeddings = list()\n",
    "                for sentence in qas_context['context_sentences_lemmas_without_stopwords']:\n",
    "                    candidate_sentences_embeddings.append(get_pretrained_word_embeddings(sentence))\n",
    "                \n",
    "                labels = set([d['answer_label'] for d in qas['answers']])\n",
    "                train_labels.append(labels)\n",
    "                \n",
    "                train_steps.append(len(candidate_sentences_embeddings))\n",
    "                \n",
    "                for i in range(len(candidate_sentences_embeddings)):\n",
    "                    feature_vector = []\n",
    "                    if q_a_combination_method == 'concatenation':\n",
    "                        feature_vector = np.concatenate((question_embedding,\n",
    "                                                         candidate_sentences_embeddings[i]))\n",
    "                    elif q_a_combination_method == 'diff_abs':\n",
    "                        feature_vector = np.abs(question_embedding - \n",
    "                                                candidate_sentences_embeddings[i])\n",
    "                    elif q_a_combination_method == 'diff_sqr':\n",
    "                        feature_vector = np.square(question_embedding - \n",
    "                                                   candidate_sentences_embeddings[i])\n",
    "                    elif q_a_combination_method == 'sum':\n",
    "                        feature_vector = question_embedding + candidate_sentences_embeddings[i]\n",
    "                    elif q_a_combination_method == 'dot_product':\n",
    "                        feature_vector = question_embedding * candidate_sentences_embeddings[i]\n",
    "                    elif q_a_combination_method == 'min':\n",
    "                        feature_vector = np.minimum(question_embedding,\n",
    "                                                    candidate_sentences_embeddings[i])            \n",
    "                    elif q_a_combination_method == 'max':\n",
    "                        feature_vector = np.maximum(question_embedding,\n",
    "                                                    candidate_sentences_embeddings[i])  \n",
    "                        \n",
    "                    train_x.append(feature_vector)\n",
    "                    label = i in labels\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return (train_x, train_y, train_steps, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:19<00:00, 22.19it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 19.10it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y, _, train_labels) = get_features(train, 'diff_abs')\n",
    "(dev_x, dev_y, dev_steps, dev_labels) = get_features(dev, 'diff_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447101\n",
      "87599\n",
      "359502\n"
     ]
    }
   ],
   "source": [
    "print((len(train_x)))\n",
    "print(np.sum(train_y == np.array([1]*len(train_y))))\n",
    "print(np.sum(train_y == np.array([0]*len(train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53967\n",
      "11436\n",
      "42531\n"
     ]
    }
   ],
   "source": [
    "print((len(dev_x)))\n",
    "print(np.sum(dev_y == np.array([1]*len(dev_y))))\n",
    "print(np.sum(dev_y == np.array([0]*len(dev_y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(train_x, train_y, test_x):\n",
    "    pred = np.zeros(len(test_x))\n",
    "\n",
    "    lr_model = LogisticRegression(C=1, dual=True)\n",
    "    lr_model.fit(train_x, train_y)\n",
    "    pred = lr_model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    return (lr_model, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(_, dev_preds) = logistic_regression(train_x, train_y, dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38079386,  0.26921253,  0.14783836,  0.20823277,  0.41239707,\n",
       "        0.27310828,  0.15625174,  0.20678496,  0.15200572,  0.19978923])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(53967,)\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_preds))\n",
    "print(dev_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_scores(y_pred, steps_lengths):\n",
    "    pred_scores_id = list()\n",
    "    steps_lengths_sum = 0\n",
    "    \n",
    "    for step_length in steps_lengths:\n",
    "        scores = {}\n",
    "        for idx in range(step_length):\n",
    "            scores[idx] = y_pred[steps_lengths_sum + idx]\n",
    "        \n",
    "        sorted_scores_id = sorted(scores, key=scores.get, reverse=True)\n",
    "        pred_scores_id.append(sorted_scores_id)\n",
    "        \n",
    "        steps_lengths_sum += step_length\n",
    "        \n",
    "    return pred_scores_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_scores_id = extract_scores(dev_preds, dev_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n",
      "53967\n",
      "10570\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_scores_id))\n",
    "print(len(dev_y))\n",
    "print(len(dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 1, 3, 2], [0, 1, 3, 2], [3, 1, 0, 2], [0, 1, 3, 2], [3, 2, 1, 0]]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(pred_scores_id[0:5])\n",
    "print(type(pred_scores_id[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False, True, False, False, False]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(dev_y[0:5])\n",
    "print(type(dev_y[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[set([1]), set([1]), set([2]), set([1]), set([3])]\n",
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(dev_labels[0:5])\n",
    "print(type(dev_labels[0:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_results = evaluation.get_results(pred_scores_id, dev_labels, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev\n",
      "AvgPrec@1: 0.752696310312 (std = 0.431444752842)\n",
      "MAP: 0.844472507558 (std = 0.264608727603)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_results(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_x\n",
    "del train_y\n",
    "del dev_x\n",
    "del dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_a_combination_method = [#'concatenation', \n",
    "                          'diff_abs', 'diff_sqr', \n",
    "                          'sum', 'dot_product', 'min', 'max']\n",
    "\n",
    "def run_LR(q_a_combination_method):\n",
    "    for q_a_comb in q_a_combination_method:\n",
    "        # feature extraction\n",
    "        (train_x, train_y, train_steps, train_labels) = get_features(train, q_a_comb)\n",
    "        (dev_x, dev_y, dev_steps, dev_labels) = get_features(dev, q_a_comb)\n",
    "        print(q_a_comb, len(train_x[0]))\n",
    "        \n",
    "        # dev set\n",
    "        (lr_model, dev_preds) = logistic_regression(train_x, train_y, dev_x)\n",
    "        dev_pred_scores_id = extract_scores(dev_preds, dev_steps)\n",
    "        \n",
    "        dev_results = evaluation.get_results(dev_pred_scores_id, dev_labels, \n",
    "                                             'dev [' + q_a_comb + ']')\n",
    "        write_results(dev_results)\n",
    "        \n",
    "        # train set, just for curiosity\n",
    "        train_preds = lr_model.predict_proba(train_x)[:, 1]\n",
    "        train_pred_scores_id = extract_scores(train_preds, train_steps)\n",
    "        \n",
    "        train_results = evaluation.get_results(train_pred_scores_id, train_labels, \n",
    "                                             'train [' + q_a_comb + ']')\n",
    "        write_results(train_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:19<00:00, 23.16it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diff_abs', 300)\n",
      "Method: dev [diff_abs]\n",
      "AvgPrec@1: 0.752696310312 (std = 0.431444752842)\n",
      "MAP: 0.844472507558 (std = 0.264608727603)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/442 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: train [diff_abs]\n",
      "AvgPrec@1: 0.730282309159 (std = 0.443813089136)\n",
      "MAP: 0.835169204597 (std = 0.27891289984)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:19<00:00, 22.80it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diff_sqr', 300)\n",
      "Method: dev [diff_sqr]\n",
      "AvgPrec@1: 0.752696310312 (std = 0.431444752842)\n",
      "MAP: 0.844228057735 (std = 0.264833626076)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/442 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: train [diff_sqr]\n",
      "AvgPrec@1: 0.727211497848 (std = 0.44539301212)\n",
      "MAP: 0.833423469318 (std = 0.279731636706)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:18<00:00, 23.40it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 19.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sum', 300)\n",
      "Method: dev [sum]\n",
      "AvgPrec@1: 0.294701986755 (std = 0.45590868138)\n",
      "MAP: 0.535056349173 (std = 0.312012221238)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/442 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: train [sum]\n",
      "AvgPrec@1: 0.280242925148 (std = 0.449117833149)\n",
      "MAP: 0.524755196253 (std = 0.316029472782)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:18<00:00, 23.84it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 20.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dot_product', 300)\n",
      "Method: dev [dot_product]\n",
      "AvgPrec@1: 0.677388836329 (std = 0.467475347741)\n",
      "MAP: 0.802098772533 (std = 0.282605987679)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/442 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: train [dot_product]\n",
      "AvgPrec@1: 0.655852235756 (std = 0.475089550095)\n",
      "MAP: 0.793331664404 (std = 0.293780571785)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:19<00:00, 22.63it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('min', 300)\n",
      "Method: dev [min]\n",
      "AvgPrec@1: 0.739262062441 (std = 0.439037202839)\n",
      "MAP: 0.836777015164 (std = 0.269044572425)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/442 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: train [min]\n",
      "AvgPrec@1: 0.714357469834 (std = 0.451719907826)\n",
      "MAP: 0.825597981509 (std = 0.283662527447)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:21<00:00, 20.35it/s]\n",
      "100%|██████████| 48/48 [00:02<00:00, 16.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('max', 300)\n",
      "Method: dev [max]\n",
      "AvgPrec@1: 0.739924314096 (std = 0.438675647267)\n",
      "MAP: 0.836958444919 (std = 0.269134960561)\n",
      "\n",
      "\n",
      "Method: train [max]\n",
      "AvgPrec@1: 0.713284398224 (std = 0.452227559393)\n",
      "MAP: 0.825082022088 (std = 0.283788186065)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_LR(q_a_combination_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
