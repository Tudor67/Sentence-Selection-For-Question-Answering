{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. [Loading preprocessed data](#1.-Loading-preprocessed-data)  \n",
    "2. [Loading pretrained word embeddings](#2.-Loading-pretrained-word-embeddings)  \n",
    "3. [Classification](#3.-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "IN_PATH = '../data/squad/'\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data_frame = pd.read_json(filename)\n",
    "    data = data_frame.to_dict(orient='list')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data(IN_PATH + 'train-v1.1-preprocessed.json')\n",
    "dev = load_data(IN_PATH + 'dev-v1.1-preprocessed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "WORD2VEC_PATH = '../word_embeddings/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "word2vec_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pretrained_word_embeddings(sentence, word_emb_dims=300):\n",
    "    global word2vec_model\n",
    "    \n",
    "    if word2vec_model is None:\n",
    "        print('load word2vec_model')\n",
    "        word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\n",
    "\n",
    "    word_embeddings = np.zeros(word_emb_dims)\n",
    "    word_emb_nr = 0\n",
    "\n",
    "    for word in sentence:\n",
    "        if word2vec_model.vocab.has_key(word):\n",
    "            word_embeddings += word2vec_model.word_vec(word)\n",
    "            word_emb_nr += 1\n",
    "\n",
    "    # a sentence is represented by the average of word_embbedings\n",
    "    if word_emb_nr != 0:\n",
    "        word_embeddings = word_embeddings / word_emb_nr\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load word2vec_model\n"
     ]
    }
   ],
   "source": [
    "get_pretrained_word_embeddings(['today', 'is', 'wednesday']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(dataset, q_a_combination_method):\n",
    "    train_x = list()\n",
    "    train_y = list()\n",
    "    train_steps = list()\n",
    "    \n",
    "    for article in tqdm(dataset['data']):\n",
    "        for qas_context in article['paragraphs']:\n",
    "            for qas in qas_context['qas']:\n",
    "                question_words = qas['question_words']\n",
    "                question_embedding = get_pretrained_word_embeddings(question_words)\n",
    "                \n",
    "                candidate_sentences_embeddings = list()\n",
    "                for sentence in qas_context['context_sentences_words']:\n",
    "                    candidate_sentences_embeddings.append(get_pretrained_word_embeddings(sentence))\n",
    "                    \n",
    "                labels = set([d['answer_label'] for d in qas['answers']])\n",
    "                \n",
    "                train_steps.append(len(candidate_sentences_embeddings))\n",
    "                \n",
    "                for i in range(len(candidate_sentences_embeddings)):\n",
    "                    feature_vector = []\n",
    "                    if q_a_combination_method == 'concatenation':\n",
    "                        feature_vector = np.concatenate((question_embedding,\n",
    "                                                         candidate_sentences_embeddings[i]))\n",
    "                    elif q_a_combination_method == 'diff_abs':\n",
    "                        feature_vector = np.abs(question_embedding - \n",
    "                                                candidate_sentences_embeddings[i])\n",
    "                    elif q_a_combination_method == 'diff_sqr':\n",
    "                        feature_vector = np.square(question_embedding - \n",
    "                                                   candidate_sentences_embeddings[i])\n",
    "                    elif q_a_combination_method == 'sum':\n",
    "                        feature_vector = question_embedding + candidate_sentences_embeddings[i]\n",
    "                                \n",
    "                    \n",
    "                    train_x.append(feature_vector)\n",
    "                    label = i in labels\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return (train_x, train_y, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:27<00:00, 15.94it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 14.03it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y, _) = get_features(train, 'diff_abs')\n",
    "(dev_x, dev_y, dev_steps) = get_features(dev, 'diff_abs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "print(len(train_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447101\n",
      "87599\n",
      "359502\n"
     ]
    }
   ],
   "source": [
    "print((len(train_x)))\n",
    "print(np.sum(train_y == np.array([1]*len(train_y))))\n",
    "print(np.sum(train_y == np.array([0]*len(train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53967\n",
      "11436\n",
      "42531\n"
     ]
    }
   ],
   "source": [
    "print((len(dev_x)))\n",
    "print(np.sum(dev_y == np.array([1]*len(dev_y))))\n",
    "print(np.sum(dev_y == np.array([0]*len(dev_y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(train_x, train_y, test_x):\n",
    "    pred = np.zeros(len(test_x))\n",
    "\n",
    "    lr_model = LogisticRegression(C=4, dual=True, class_weight='balanced')\n",
    "    lr_model.fit(train_x, train_y)\n",
    "    pred = lr_model.predict_proba(test_x)[:, 1]\n",
    "\n",
    "    return (lr_model, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, dev_preds) = logistic_regression(train_x, train_y, dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.6701109 ,  0.46673225,  0.42017233,  0.56337556,  0.70080548,\n",
       "        0.49292632,  0.46756613,  0.57458492,  0.21215984,  0.20779809])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_preds[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(53967,)\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_preds))\n",
    "print(dev_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dev_preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_scores(y_pred, steps_lengths):\n",
    "    pred_scores = list()\n",
    "    steps_lengths_sum = 0\n",
    "    \n",
    "    for step_length in steps_lengths:\n",
    "        scores = {}\n",
    "        for idx in range(step_length):\n",
    "            scores[idx] = y_pred[steps_lengths_sum + idx]\n",
    "        \n",
    "        sorted_scores = sorted(scores, key=scores.get, reverse=True)\n",
    "        pred_scores.append(sorted_scores)\n",
    "        \n",
    "        steps_lengths_sum += step_length\n",
    "        \n",
    "    return pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = extract_scores(dev_preds, dev_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluation\n",
    "\n",
    "def get_results(pred_scores, y, method):\n",
    "    results = {'Method': method, 'Prec@1': [], 'Prec@5': [], 'Prec@10': [],\n",
    "           'AvgPrec': [], 'MAP': 0} \n",
    "    \n",
    "    for i in range(len(pred_scores)):\n",
    "        y_pred = pred_scores[i]\n",
    "        results['Prec@1'].append(evaluation.precision_at_k(y_pred, y, k=1))\n",
    "        results['AvgPrec'].append(evaluation.average_precision(y_pred, y))\n",
    "    \n",
    "    # evaluation (MAP - mean average precision)\n",
    "    results['MAP'] = np.mean(results['AvgPrec'])\n",
    "    results['StdAP'] = np.std(results['AvgPrec'])\n",
    "    results['AvgPrec@1'] = np.mean(results['Prec@1'])\n",
    "    results['StdPrec@1'] = np.std(results['Prec@1'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_results = get_results(pred_scores, dev_y, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(results):\n",
    "    print('Method: {}'.format(results['Method']))\n",
    "    print('AvgPrec@1: {} (std = {})'.format(results['AvgPrec@1'], results['StdPrec@1']))\n",
    "    print('MAP: {} (std = {})'.format(results['MAP'], results['StdAP']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev\n",
      "AvgPrec@1: 0.545789971618 (std = 0.497898863726)\n",
      "MAP: 0.674179773456 (std = 0.258354658703)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_results(dev_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del train_x\n",
    "del train_y\n",
    "del dev_x\n",
    "del dev_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_a_combination_method = ['concatenation', 'diff_abs', 'diff_sqr', 'sum']\n",
    "\n",
    "def run_LR(q_a_combination_method):\n",
    "    for q_a_comb in q_a_combination_method:\n",
    "        # feature extraction\n",
    "        (train_x, train_y, train_steps) = get_features(train, q_a_comb)\n",
    "        (dev_x, dev_y, dev_steps) = get_features(dev, q_a_comb)\n",
    "        print(q_a_comb, len(train_x[0]))\n",
    "        \n",
    "        # dev set\n",
    "        (lr_model, dev_preds) = logistic_regression(train_x, train_y, dev_x)\n",
    "        dev_pred_scores = extract_scores(dev_preds, dev_steps)\n",
    "        \n",
    "        dev_results = get_results(dev_pred_scores, dev_y, 'dev [' + q_a_comb + ']')\n",
    "        write_results(dev_results)\n",
    "        \n",
    "        # train set, just for curiosity\n",
    "        '''\n",
    "        train_pred = lr_model.predict_proba(train_x)\n",
    "        train_pred_scores = extract_scores(train_y, train_steps)\n",
    "        \n",
    "        train_results = get_results(train_pred_scores, train_y, 'train [' + q_a_comb + ']')\n",
    "        write_results(train_results)\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:27<00:00, 15.97it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('concatenation', 600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<01:14,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [concatenation]\n",
      "AvgPrec@1: 0.54389782403 (std = 0.498069253262)\n",
      "MAP: 0.671481101023 (std = 0.252198362598)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:38<00:00, 11.46it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diff_abs', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:47,  9.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [diff_abs]\n",
      "AvgPrec@1: 0.545789971618 (std = 0.497898863726)\n",
      "MAP: 0.674179773456 (std = 0.258354658703)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:26<00:00, 16.53it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('diff_sqr', 300)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/442 [00:00<00:57,  7.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev [diff_sqr]\n",
      "AvgPrec@1: 0.547209082308 (std = 0.497766313191)\n",
      "MAP: 0.675022769117 (std = 0.25850526639)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:27<00:00, 15.87it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sum', 300)\n",
      "Method: dev [sum]\n",
      "AvgPrec@1: 0.53793755913 (std = 0.498558664158)\n",
      "MAP: 0.670287341404 (std = 0.252211717281)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_LR(q_a_combination_method)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
