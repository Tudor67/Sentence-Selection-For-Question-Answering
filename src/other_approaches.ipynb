{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content\n",
    "1. [Loading preprocessed data](#1.-Loading-preprocessed-data)  \n",
    "2. [Loading pretrained word embeddings](#2.-Loading-pretrained-word-embeddings)  \n",
    "3. [Classification](#3.-Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "IN_PATH = '../data/squad/'\n",
    "\n",
    "\n",
    "def load_data(filename):\n",
    "    data_frame = pd.read_json(filename)\n",
    "    data = data_frame.to_dict(orient='list')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data(IN_PATH + 'train-v1.1-preprocessed.json')\n",
    "dev = load_data(IN_PATH + 'dev-v1.1-preprocessed.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading pretrained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "WORD2VEC_PATH = '../word_embeddings/GoogleNews-vectors-negative300.bin'\n",
    "\n",
    "word2vec_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pretrained_word_embeddings(sentence, word_emb_dims=300):\n",
    "    global word2vec_model\n",
    "    \n",
    "    if word2vec_model is None:\n",
    "        print('load word2vec_model')\n",
    "        word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(WORD2VEC_PATH, binary=True)\n",
    "\n",
    "    word_embeddings = np.zeros(word_emb_dims)\n",
    "    word_emb_nr = 0\n",
    "\n",
    "    for word in sentence:\n",
    "        if word2vec_model.vocab.has_key(word):\n",
    "            word_embeddings += word2vec_model.word_vec(word)\n",
    "            word_emb_nr += 1\n",
    "\n",
    "    # a sentence is represented by the average of word_embbedings\n",
    "    if word_emb_nr != 0:\n",
    "        word_embeddings = word_embeddings / word_emb_nr\n",
    "\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load word2vec_model\n"
     ]
    }
   ],
   "source": [
    "get_pretrained_word_embeddings(['today', 'is', 'wednesday']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(dataset):\n",
    "    train_x = list()\n",
    "    train_y = list()\n",
    "    train_steps = list()\n",
    "    \n",
    "    for article in tqdm(dataset['data']):\n",
    "        for qas_context in article['paragraphs']:\n",
    "            for qas in qas_context['qas']:\n",
    "                question_words = qas['question_words']\n",
    "                question_embedding = get_pretrained_word_embeddings(question_words)\n",
    "                \n",
    "                candidate_sentences_embeddings = list()\n",
    "                for sentence in qas_context['context_sentences_words']:\n",
    "                    candidate_sentences_embeddings.append(get_pretrained_word_embeddings(sentence))\n",
    "                    \n",
    "                labels = set([d['answer_label'] for d in qas['answers']])\n",
    "                \n",
    "                train_steps.append(len(candidate_sentences_embeddings))\n",
    "                \n",
    "                for i in range(len(candidate_sentences_embeddings)):\n",
    "                    train_x.append(question_embedding + candidate_sentences_embeddings[i])\n",
    "                    label = i in labels\n",
    "                    train_y.append(label)\n",
    "                    \n",
    "    return (train_x, train_y, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 442/442 [00:28<00:00, 15.25it/s]\n",
      "100%|██████████| 48/48 [00:03<00:00, 12.75it/s]\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y, _) = get_features(train)\n",
    "(dev_x, dev_y, dev_steps) = get_features(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "447101\n",
      "87599\n",
      "359502\n"
     ]
    }
   ],
   "source": [
    "print((len(train_x)))\n",
    "print(np.sum(train_y == np.array([1]*len(train_y))))\n",
    "print(np.sum(train_y == np.array([0]*len(train_y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53967\n",
      "11436\n",
      "42531\n"
     ]
    }
   ],
   "source": [
    "print((len(dev_x)))\n",
    "print(np.sum(dev_y == np.array([1]*len(dev_y))))\n",
    "print(np.sum(dev_y == np.array([0]*len(dev_y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(train_x, train_y, test_x):\n",
    "    pred = np.zeros(len(test_x))\n",
    "\n",
    "    lr_model = LogisticRegression(C=4, dual=True, class_weight='balanced')\n",
    "    lr_model.fit(train_x, train_y)\n",
    "    pred = lr_model.predict_proba(test_x)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logistic_regression(train_x, train_y, dev_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40176146,  0.59823854],\n",
       "       [ 0.44002845,  0.55997155],\n",
       "       [ 0.44106264,  0.55893736],\n",
       "       [ 0.43749417,  0.56250583],\n",
       "       [ 0.41188011,  0.58811989],\n",
       "       [ 0.4503853 ,  0.5496147 ],\n",
       "       [ 0.45142421,  0.54857579],\n",
       "       [ 0.44783908,  0.55216092],\n",
       "       [ 0.49391697,  0.50608303],\n",
       "       [ 0.53313913,  0.46686087]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_scores(y_pred, steps_lengths):\n",
    "    pred_scores = list()\n",
    "    steps_lengths_sum = 0\n",
    "    \n",
    "    for step_length in steps_lengths:\n",
    "        scores = {}\n",
    "        for idx in range(step_length):\n",
    "            scores[idx] = y_pred[steps_lengths_sum + idx]\n",
    "        \n",
    "        sorted_scores = sorted(scores, key=scores.get, reverse=True)\n",
    "        pred_scores.append(sorted_scores)\n",
    "        \n",
    "        steps_lengths_sum += step_length\n",
    "        \n",
    "    return pred_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_scores = extract_scores(dev_y, dev_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10570\n"
     ]
    }
   ],
   "source": [
    "print(len(pred_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import evaluation\n",
    "\n",
    "def get_results(pred_scores, y, method):\n",
    "    results = {'Method': method, 'Prec@1': [], 'Prec@5': [], 'Prec@10': [],\n",
    "           'AvgPrec': [], 'MAP': 0} \n",
    "    \n",
    "    for i in range(len(pred_scores)):\n",
    "        y_pred = pred_scores[i]\n",
    "        results['Prec@1'].append(evaluation.precision_at_k(y_pred, y, k=1))\n",
    "        results['AvgPrec'].append(evaluation.average_precision(y_pred, y))\n",
    "    \n",
    "    # evaluation (MAP - mean average precision)\n",
    "    results['MAP'] = np.mean(results['AvgPrec'])\n",
    "    results['StdAP'] = np.std(results['AvgPrec'])\n",
    "    results['AvgPrec@1'] = np.mean(results['Prec@1'])\n",
    "    results['StdPrec@1'] = np.std(results['Prec@1'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_results = get_results(pred_scores, dev_y, 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_results(results):\n",
    "    print('Method: {}'.format(results['Method']))\n",
    "    print('AvgPrec@1: {} (std = {})'.format(results['AvgPrec@1'], results['StdPrec@1']))\n",
    "    print('MAP: {} (std = {})'.format(results['MAP'], results['StdAP']))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: dev\n",
      "AvgPrec@1: 0.576348155156 (std = 0.494136579504)\n",
      "MAP: 0.813787448754 (std = 0.209770386056)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "write_results(dev_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
